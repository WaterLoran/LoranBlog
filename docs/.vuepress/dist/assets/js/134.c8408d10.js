(window.webpackJsonp=window.webpackJsonp||[]).push([[134],{561:function(t,s,a){"use strict";a.r(s);var n=a(2),r=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("p",[t._v("你的代码片段显示了一个典型的使用 "),s("strong",[t._v("FAISS")]),t._v("（Facebook AI Similarity Search）与大语言模型（LLM）生成向量嵌入结合的工作流。这种方式将语义嵌入（embeddings）存储在向量数据库中，并利用向量检索实现高效的搜索或问答功能。")]),t._v(" "),s("p",[t._v("以下是相关知识体系的详细解释：")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"_1-faiss-简介"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-faiss-简介"}},[t._v("#")]),t._v(" "),s("strong",[t._v("1. FAISS 简介")])]),t._v(" "),s("p",[s("strong",[t._v("FAISS")]),t._v(" 是一个开源的高效向量搜索库，由 Facebook AI 开发，用于处理和搜索稠密向量数据。")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("主要功能")]),t._v("：\n"),s("ul",[s("li",[t._v("高速相似性搜索（k 近邻搜索）。")]),t._v(" "),s("li",[t._v("支持百万级甚至更大规模向量的存储和检索。")])])]),t._v(" "),s("li",[s("strong",[t._v("特点")]),t._v("：\n"),s("ul",[s("li",[t._v("支持多种索引类型（Flat、IVF、HNSW 等），在内存使用和搜索速度之间找到平衡。")]),t._v(" "),s("li",[t._v("高度优化，支持 GPU 加速。")])])])]),t._v(" "),s("p",[t._v("FAISS 本身不生成向量，它需要通过其他工具（如大模型）生成输入向量。")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"_2-向量嵌入-embeddings-简介"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-向量嵌入-embeddings-简介"}},[t._v("#")]),t._v(" "),s("strong",[t._v("2. 向量嵌入（Embeddings）简介")])]),t._v(" "),s("h3",{attrs:{id:"什么是向量嵌入"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#什么是向量嵌入"}},[t._v("#")]),t._v(" "),s("strong",[t._v("什么是向量嵌入")])]),t._v(" "),s("ul",[s("li",[t._v("向量嵌入是一种用向量表示文本、图像或其他数据的方式，捕捉其语义信息。")]),t._v(" "),s("li",[t._v("例如，语义相似的文本会映射到相近的向量空间中。")])]),t._v(" "),s("h3",{attrs:{id:"如何生成向量嵌入"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何生成向量嵌入"}},[t._v("#")]),t._v(" "),s("strong",[t._v("如何生成向量嵌入")])]),t._v(" "),s("p",[t._v("通常由预训练的大模型生成，例如：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("OpenAI 模型")]),t._v("：如 "),s("code",[t._v("text-embedding-ada-002")]),t._v("。")]),t._v(" "),s("li",[s("strong",[t._v("Hugging Face 模型")]),t._v("：如 Sentence-BERT、DistilBERT。")]),t._v(" "),s("li",[s("strong",[t._v("本地模型")]),t._v("：如 GloVe、FastText 等。")])]),t._v(" "),s("p",[t._v("在你的代码中：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("embeddings "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" OpenAIEmbeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    openai_api_key"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("api_key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    openai_api_base"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("base_url\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("code",[t._v("OpenAIEmbeddings")]),t._v(" 使用 OpenAI 的 API 来生成嵌入。")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"_3-faiss-与大模型的关系"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-faiss-与大模型的关系"}},[t._v("#")]),t._v(" "),s("strong",[t._v("3. FAISS 与大模型的关系")])]),t._v(" "),s("h3",{attrs:{id:"为什么-faiss-需要大模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#为什么-faiss-需要大模型"}},[t._v("#")]),t._v(" "),s("strong",[t._v("为什么 FAISS 需要大模型？")])]),t._v(" "),s("p",[t._v("FAISS 是一个索引和检索工具，不能直接生成向量。它依赖于大模型生成的嵌入向量作为输入。例如：")]),t._v(" "),s("ol",[s("li",[t._v("输入文本。")]),t._v(" "),s("li",[t._v("用大模型将文本转化为嵌入向量。")]),t._v(" "),s("li",[t._v("使用 FAISS 将嵌入向量存储到数据库中。")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 示例：将文本转为向量并存入 FAISS")]),t._v("\ntexts "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hello, world!"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"How are you?"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ndocsearch "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" FAISS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_texts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("texts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" embeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"工作流程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#工作流程"}},[t._v("#")]),t._v(" "),s("strong",[t._v("工作流程")])]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("嵌入生成")]),t._v("：使用大模型生成语义向量。")]),t._v(" "),s("li",[s("strong",[t._v("向量存储")]),t._v("：将嵌入存入 FAISS 索引。")]),t._v(" "),s("li",[s("strong",[t._v("检索")]),t._v("：\n"),s("ul",[s("li",[t._v("输入查询，通过同样的大模型生成查询向量。")]),t._v(" "),s("li",[t._v("FAISS 计算查询向量与存储向量的相似性，返回最相近的结果。")])])])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"_4-应用场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-应用场景"}},[t._v("#")]),t._v(" "),s("strong",[t._v("4. 应用场景")])]),t._v(" "),s("h3",{attrs:{id:"典型应用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#典型应用"}},[t._v("#")]),t._v(" "),s("strong",[t._v("典型应用")])]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("文档检索")]),t._v(" "),s("ul",[s("li",[t._v("例如搜索引擎：将所有文档嵌入存入 FAISS，用查询检索最相关文档。")])])]),t._v(" "),s("li",[s("strong",[t._v("问答系统")]),t._v(" "),s("ul",[s("li",[t._v("使用向量检索找到与问题最相关的上下文，再用大语言模型生成答案。")])])]),t._v(" "),s("li",[s("strong",[t._v("推荐系统")]),t._v(" "),s("ul",[s("li",[t._v("将用户行为嵌入存入 FAISS，基于相似性推荐内容。")])])])]),t._v(" "),s("h3",{attrs:{id:"实际例子"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#实际例子"}},[t._v("#")]),t._v(" "),s("strong",[t._v("实际例子")])]),t._v(" "),s("p",[t._v("以下代码展示了如何结合 FAISS 和 OpenAI 嵌入构建问答系统：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vectorstores "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" FAISS\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("embeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openai "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" OpenAIEmbeddings\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 加载文本数据")]),t._v("\ntexts "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What is AI?"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Explain Machine Learning."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What is Deep Learning?"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 使用 OpenAI 生成嵌入")]),t._v("\nembeddings "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" OpenAIEmbeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("openai_api_key"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"your_api_key"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndocsearch "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" FAISS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_texts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("texts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" embeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 查询")]),t._v("\nquery "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What is ML?"')]),t._v("\nquery_embedding "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" embeddings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("embed_query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresult "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" docsearch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("similarity_search"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("hr"),t._v(" "),s("h2",{attrs:{id:"_5-替代嵌入模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-替代嵌入模型"}},[t._v("#")]),t._v(" "),s("strong",[t._v("5. 替代嵌入模型")])]),t._v(" "),s("p",[t._v("如果不使用 OpenAI 嵌入，可以选择以下开源模型：")]),t._v(" "),s("ol",[s("li",[s("p",[s("strong",[t._v("Sentence-BERT")])]),t._v(" "),s("ul",[s("li",[t._v("基于 BERT 的句子嵌入模型。")]),t._v(" "),s("li",[t._v("Hugging Face 加载："),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sentence_transformers "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SentenceTransformer\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SentenceTransformer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'all-MiniLM-L6-v2'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nembeddings "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" text "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" texts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])])])])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("GloVe/FastText")])]),t._v(" "),s("ul",[s("li",[t._v("静态嵌入模型。")]),t._v(" "),s("li",[t._v("适用于资源受限的场景。")])])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("本地部署模型")])]),t._v(" "),s("ul",[s("li",[t._v("使用 Hugging Face 模型实现完全离线的嵌入生成。")])])])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"_6-faiss-优化与扩展"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6-faiss-优化与扩展"}},[t._v("#")]),t._v(" "),s("strong",[t._v("6. FAISS 优化与扩展")])]),t._v(" "),s("h3",{attrs:{id:"索引优化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#索引优化"}},[t._v("#")]),t._v(" "),s("strong",[t._v("索引优化")])]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("Flat 索引")]),t._v("：\n"),s("ul",[s("li",[t._v("精确检索，但内存占用高。")]),t._v(" "),s("li",[t._v("示例："),s("code",[t._v("faiss.IndexFlatL2()")])])])]),t._v(" "),s("li",[s("strong",[t._v("IVF 索引")]),t._v("：\n"),s("ul",[s("li",[t._v("适合大规模数据，分桶后进行近似检索。")]),t._v(" "),s("li",[t._v("示例："),s("code",[t._v("faiss.IndexIVFFlat()")])])])]),t._v(" "),s("li",[s("strong",[t._v("HNSW 索引")]),t._v("：\n"),s("ul",[s("li",[t._v("基于图的检索方式，适合海量数据的近似检索。")])])])]),t._v(" "),s("h3",{attrs:{id:"分布式与并行"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式与并行"}},[t._v("#")]),t._v(" "),s("strong",[t._v("分布式与并行")])]),t._v(" "),s("ul",[s("li",[t._v("使用多个 GPU 提高大规模检索性能。")]),t._v(" "),s("li",[t._v("使用 FAISS 的 Python 接口并行化批量查询。")])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"_7-商用部署注意事项"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7-商用部署注意事项"}},[t._v("#")]),t._v(" "),s("strong",[t._v("7. 商用部署注意事项")])]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("API 使用许可")]),t._v("：\n"),s("ul",[s("li",[t._v("如果使用 OpenAI API，需遵守其商用政策。")])])]),t._v(" "),s("li",[s("strong",[t._v("数据隐私")]),t._v("：\n"),s("ul",[s("li",[t._v("确保嵌入生成和存储的文本数据符合隐私法规（如 GDPR）。")])])]),t._v(" "),s("li",[s("strong",[t._v("成本控制")]),t._v("：\n"),s("ul",[s("li",[t._v("考虑本地化部署以降低 API 调用费用。")])])])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" "),s("strong",[t._v("总结")])]),t._v(" "),s("p",[t._v("FAISS 是一个高效的向量检索工具，但它需要大模型生成嵌入向量。通过结合大模型生成的嵌入，FAISS 可以应用于多种场景，如文档检索、推荐系统、问答系统等。您可以选择开源或商用的大模型来生成嵌入，根据需求和预算选择适合的部署方式。如果需要具体部署建议或代码示例，请进一步联系！")])])}),[],!1,null,null,null);s.default=r.exports}}]);