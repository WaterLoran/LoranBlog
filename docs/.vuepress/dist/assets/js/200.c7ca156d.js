(window.webpackJsonp=window.webpackJsonp||[]).push([[200],{632:function(a,t,v){"use strict";v.r(t);var _=v(2),s=Object(_.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"一次性能交付测试经历"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#一次性能交付测试经历"}},[a._v("#")]),a._v(" 一次性能交付测试经历")]),a._v(" "),t("h2",{attrs:{id:"背景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#背景"}},[a._v("#")]),a._v(" 背景")]),a._v(" "),t("p",[a._v("公司给某个大客户做定制化开发, 于是需要甲方需要做性能验收, 于是派出了部门里我这个测试, 所以这次测试活动的目的, 就是向甲方证明我们的软件的性能是能够满足要求.")]),a._v(" "),t("h2",{attrs:{id:"交付软件的业务分析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#交付软件的业务分析"}},[a._v("#")]),a._v(" 交付软件的业务分析")]),a._v(" "),t("p",[a._v("我们公司的软件是一个XX管理平台, 实质上就是一个数据管理平台, 分来A端, 和B端, A端主要是设计生产各类数据, 比如文本数据, 图数据, 链接表单数据这些, B端则主要是用于做这些数据的简单聚合和统计并最后并展示出来, 算是一个很经典的BPM系统. 主要用于客户公司的IT管理体系的建设. 目标是和客户公司的IT体系融合起来, 打通各类数据, 为生产和管理助力.")]),a._v(" "),t("h2",{attrs:{id:"识别验收场景及选取"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#识别验收场景及选取"}},[a._v("#")]),a._v(" 识别验收场景及选取")]),a._v(" "),t("p",[a._v("在我看来, 我们的软件主要主要有3个使用阶段,")]),a._v(" "),t("ol",[t("li",[a._v("第一阶段: 90%的访问量在A端, 10%的访问量在B端")]),a._v(" "),t("li",[a._v("第二阶段: 50%的访问量在A端, 50%的访问量在B端")]),a._v(" "),t("li",[a._v("第三阶段: 10%的访问量在A端, 90%的访问量在B端")])]),a._v(" "),t("p",[a._v("另外, A端主要用于生产数据, 实际上, 最多也就是100人在使用, 而B端用于展示和供普通员工学习使用, 有可能是会达到5W甚至10W人的使用的.")]),a._v(" "),t("h3",{attrs:{id:"和客户公司验收人员的沟通确认"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#和客户公司验收人员的沟通确认"}},[a._v("#")]),a._v(" 和客户公司验收人员的沟通确认")]),a._v(" "),t("p",[a._v("不得不说, 客户公司从外包公司找来的性能验收人员, 技术和经验都非常不错, 有10年工作经验, 更是接触过各类软件系统, 嵌入式的, CS架构的, BS架构的, 工具类的, 等等各类的, 可能基础设施如私有云和交换器来的没有接触过. 不过对于客户公司的IT体系的建设和验收, 他的能力真的是绰绰有余的.")]),a._v(" "),t("p",[a._v("他的经验非常丰富, 在B端验收这块, 我是真没有多少主动. 整个过程几乎是他主导的.")]),a._v(" "),t("p",[a._v("他大概很快, 就能分析出来, 那些功能是最经常使用的, 以及那些地方是数据量增长最大的.")]),a._v(" "),t("p",[a._v("他首先询问我, 我们自己要测试哪些场景, 我就直接根据之前的经验, 给他说明了, 好几个页面, 说了好几个功能, 然后他就接过来软件系统一看, 一个个询问, 那些功能怎么使用, 会产生那些数据, 很快, 他就知道了, 那些地方会有性能瓶颈, 会是需要关注的地方. 回头我一看, 我也是觉得非常有道理. 最后他是选择了, 首页加载的场景, 以及其他几个类型页面的加载, 以及, 几个常用功能的场景, 以及一些页面的搜索功能, 算是非常经典以及非常有针对性的了.")]),a._v(" "),t("h3",{attrs:{id:"题外话之和之前的性能测试比较"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#题外话之和之前的性能测试比较"}},[a._v("#")]),a._v(" 题外话之和之前的性能测试比较")]),a._v(" "),t("p",[a._v("那时候, 我是非常惊讶以及佩服的, 比起我以前第二家公司的基础设施软件产品, 这个性能验收同事, 经验非常独到, 分析的又快, 做决定也非常有信心, 简直就是一针见血. 我第二家公司的时候, 明显是性能要求极高, 但是, 性能测试做起来非常简单的, 毕竟就是那些场景, 以及之前就已经做了很多年时间了, 客户那边的性能诉求, 客户都能直接告诉你了, 任何的方法工具和流程和标准, 都一清二楚, 做起来是非常简单的. 第二家公司的时候, 各种性能测试主要就是堆请求量然后去观察他的平稳度, 以及检测响应恢复能力. 测试方面的工作内容很简单, 反而是开发的定位和调优会比较吃力.")]),a._v(" "),t("h2",{attrs:{id:"环境搭建"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#环境搭建"}},[a._v("#")]),a._v(" 环境搭建")]),a._v(" "),t("p",[a._v("我们的软件交付, 是属于典型的B端交付, 而且是私有化部署的, 最开始让我有点惊讶的还是, 在客户那边有一个测试环境, 也还有一个生产环境. 测试环境的是24U64G的硬件规格外加一个独立的数据库, 甲方的性能验收人员给的意见是, 直接现在测试环境做测试, 一个是如果在测试环境的性能都能满足的话, 就不用在生产环境做测试了, 生产环境的硬件规格是测试环境的2倍. 另外不在生产环境做测试的一个好处就是, 避免性能测试留下来的数据污染, 这个风险多少有点不可控的样子.")]),a._v(" "),t("p",[a._v("最后在测试环境测试, 数据库还单独迁移到了一个高性能硬件服务器的环境. 为的就是能够测试出最接近生产环境的数据.")]),a._v(" "),t("h2",{attrs:{id:"测试脚本准备"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#测试脚本准备"}},[a._v("#")]),a._v(" 测试脚本准备")]),a._v(" "),t("p",[a._v("因为是要测试某页面的加载功能, 所以, 会涉及很多请求, 所以,这个时候用jmeter就是一个非常好的工具, 不同于版本迭代时候的性能测试, 那个时候可以用runnerGo, 也就是一种面向于于团队协作和数据管理和数据比对分析的平台. 在这里Jmeter主打的就是一个方便, 能够方便录制各类请求, 以及方便去组合各类请求的比例.")]),a._v(" "),t("p",[a._v("在这个过程中, 验收同事, 还给我介绍了meterSphere的请求录制工具, 确实非常方便, 录制好之后, 还直接将目标网站的域名端口信息给抽离出变量来. 从此以后, 准备脚本就不是一项繁琐重复的工作, 就不会那么恼人, 比起Jmeter自带的录制工具, 还少了代理配置, 和多个步骤配置的麻烦")]),a._v(" "),t("p",[a._v("最后, 验收同事还反复叮嘱我, 测试脚本中, 还要加上断言, 因为还是少量存在响应为200, 但是实际上为失败的情况, 毕竟有些公司的软甲, 架构比较差, 有些东西不算是严谨. 才会出现这种情况")]),a._v(" "),t("h2",{attrs:{id:"被测数据准备"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#被测数据准备"}},[a._v("#")]),a._v(" 被测数据准备")]),a._v(" "),t("p",[a._v("这个是挺重要的点, 我问过很多开发, 他们说的500W的数据, 用sql查询起来, 也是很快的, 最多就在100ms以内, 在这个过程中, 主要就是要写好sql, 而不是写低性能的sql, 否则有可能长达2-5S都有可能.")]),a._v(" "),t("p",[a._v("验收中, 这也是一个比较大的关注点, 软件刚交付的时候, 数据量少, 是能够满足性能要求的, 但是在持续使用之后, 性能就会变得很差, 主要就是因为数据量变大了, 很常见的场景就是, 医院的IT系统, 有时候打开一个界面都要5秒到10秒, 而这类软件交付, 一旦把钱收到手了, 性能优化, 就变得不可能了, 就变成了要继续掏钱的工作内容了. 所以可见医院的IT系统采购和验收能力是很差的. 以及交付到医院的IT系统的供应商, 通常在软件设计能力上不会是很优秀的那种.")]),a._v(" "),t("p",[a._v("所以工作上的话, 被测数据的准备, 主要就针对于, 常用场景产生的增量数据. 并且有可能是只额吉根据未来5-10年的数据增长量为目标的.")]),a._v(" "),t("h2",{attrs:{id:"如何计算出目标性能诉求"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何计算出目标性能诉求"}},[a._v("#")]),a._v(" 如何计算出目标性能诉求")]),a._v(" "),t("p",[a._v("跟C端互联网产品的性能诉求不同, C端胡亮网APP的性能诉求, 通常一定程度上和用户数量关联, 并且有可能会因为业务爆火, 下载量剧增后, 性能诉求暴增10倍都是有可能的.")]),a._v(" "),t("p",[a._v("B端产品主要的使用者是客户公司的员工, 性能诉求还是算比较稳定的, 最多就还是客户公司人员增加一倍, 从2W到4W, 或者, 可能就5W到10W, 通过直接调整硬件规格还是能够解决整体的容量问题的.")]),a._v(" "),t("p",[a._v("在这个项目中, 采用的是28原则, 即客户公司的80%员工在20%的时间去使用, 假设客户公司10W, 那个就是10W X 80% 的员工, 在8H X20%的 时间去使用, 计算写来就是 10W X 0.8 / (3600S  X 2) =  80000 / 7200 S = 11.11, 也就是11.11个事务, 通常来讲就是, 这一秒中, 会有11个事务(事务指的是某个页面加载, 或者某个点击, 某个表单的提交, 或者某个数据查询, 即用户维度关注的一个操作), 然后再按照预期的3-5倍的规格 去翻倍, 以应对未来的性能增量和性能激增场景.")]),a._v(" "),t("p",[a._v("最后选取的是3倍的容量.  即11.11 X 3  = 33.3  (这里的数据, 仅仅为计算示例和实际数量无直接关系)")]),a._v(" "),t("h2",{attrs:{id:"测试过程中的调整"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#测试过程中的调整"}},[a._v("#")]),a._v(" 测试过程中的调整")]),a._v(" "),t("h3",{attrs:{id:"测试脚本的调整"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#测试脚本的调整"}},[a._v("#")]),a._v(" 测试脚本的调整")]),a._v(" "),t("p",[a._v("过程中还是发现有些场景不太满足, 在不想做性能优化的时候, 就会想办法在尽可能允许的范围内去测试出满足目标的性能, 以完成性能交付测试, 这个过程中, 其实也是尽最大程度来模拟真实请求, 在F12抓包的过程中, 可以发现前端下发的请求是有5-6个请求, 同时下发的, 所以, 在测试脚本中, 可以加入并行控制器, 即允许Jmeter脚本能够同时发送5个请求. 这样子操作的话, 实际上能够测试出大于好5-10%的性能.")]),a._v(" "),t("h3",{attrs:{id:"分布式服务数量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分布式服务数量"}},[a._v("#")]),a._v(" 分布式服务数量")]),a._v(" "),t("p",[a._v("刚刚给客户部署的时候, 有时候不太清楚各类请求的数量, 所以, 各类服务的数量也就是, 随便指定一下, 实际要测试出目标容量的话, 就要根据实际的业务诉求期望来计算, 以及根据实际情况来调整各类服务的数量. 最后也确实是调整了某个服务的数量, 所以, 这个过程是在约定的硬件容量下去调整服务数量来灵活应对业务变化. 所以, 这也是一个性能优化的方向.")]),a._v(" "),t("h2",{attrs:{id:"前端性能基准测试"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#前端性能基准测试"}},[a._v("#")]),a._v(" 前端性能基准测试")]),a._v(" "),t("p",[a._v("这个前端性能基准测试, 我也是第一次碰到, 主要做法就是在新版谷歌浏览器, 通过点击F12打开开发者工具, 用里面的lightHouse来测试页面的加载过程和性能情况. 最主要关心的数据, 即该工具展示出来的数据, 上面的那些数据都是业界的优秀经验, 那些性能数据诉求, 都算是比较合理的, 所以在这个过程中, 直接参照lightHouse的数据即可, 但是旧版的一些指标, 在新版浏览器中是找不到的了, 比如可交互时间, 这个性能指标, 看着非常有用, 以及非常贴合实际, 但是最终也还是一个贝塔指标, 因为这个指标的确定很不精准, 单从响应层面和渲染层面而言是看不出来的, 所以这个指标, 在最新版的chrome浏览器中是已经没有了的.")]),a._v(" "),t("h2",{attrs:{id:"新的性能指标"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#新的性能指标"}},[a._v("#")]),a._v(" 新的性能指标")]),a._v(" "),t("p",[a._v("这个指标就是 事务量. 事务指的是, 用户的一次行为, 比如某个页面加载, 一次点击, 一次表单提交, 一次搜索, 这样子的指标会比较贴合B端的使用场景. 区别与C端互联网产品, 他们的功能通常是以接口来实现的, 一个事务通常就是2-3个接口, 所以通常关注的维度就会停留在某个http接口的性能方面.")]),a._v(" "),t("p",[a._v("这个其实也是, 我第一次做这种性能交付的时候, 才接触到的性能指标. 回头一看确实是非常有用的.")]),a._v(" "),t("h2",{attrs:{id:"并发测试"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#并发测试"}},[a._v("#")]),a._v(" 并发测试")]),a._v(" "),t("p",[a._v("在这里的测试中, 最终是期望, 能够满足上面计算出来33 个事务量的目标, 所以, 就直接选取性能消耗最大的场景, 以及未来可能性能变化诉求最大的场景来测试, 所以, 场景的选取自然是少不了首页加载.")]),a._v(" "),t("p",[a._v("所以, 这个场景,最终关注的时候, 能不能同时满足目标容量的人去使用这个软件, 也就是最终的性能目标诉求了.")]),a._v(" "),t("h2",{attrs:{id:"压力测试"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#压力测试"}},[a._v("#")]),a._v(" 压力测试")]),a._v(" "),t("p",[a._v("做这个测试, 目的是为了查看软件在压力情况下, 是否会崩溃, 比如某个时间段使用量的激增会不会导致软件系统的损坏和恢复性. 这种极大容量的性能激增, 谁也说不准, 也很难在合同层面去提这种诉求, 所以, 最多就只能期望软件在大性能的情况下不要崩溃就行, 并且如果崩溃了, 在请求量下降后, 也能够执行恢复. 毕竟100W以内的软件, 大概也就只能期望到这种程度了, 不像基础设施, 要能够达到99.9999%的可靠性.")]),a._v(" "),t("h2",{attrs:{id:"负载测试"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#负载测试"}},[a._v("#")]),a._v(" 负载测试")]),a._v(" "),t("p",[a._v("这个过程, 主要是整体看一下, 系统的性能表现随着请求量的变化有无巨大变化, 从而看出某一块的软件性能差, 从而分析会不会因为这个场景,也就是这个模块逻辑而引入其他性能问题, 我觉得在性能交付场景来看的话, 更多是关注这个点.")]),a._v(" "),t("p",[a._v("而如果是在C端App场景, 这个负载测试, 更多的是去分析代码引入的性能平稳度, 以及容量随服务数量增加的线性变化的可能性. 如果不能线性, 或者离线性比较远, 或者趋向于, log函数那种性能响应曲线的形状的话, 就不会一个好的性能表现, 也就随对应的代码需要优化了.")]),a._v(" "),t("h2",{attrs:{id:"综合场景的长稳测试"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#综合场景的长稳测试"}},[a._v("#")]),a._v(" 综合场景的长稳测试")]),a._v(" "),t("p",[a._v("这个场景其实也是最头疼的, 关键的一个点是各个场景的比例, 交付方尽可能往自己有利的方向去引导, 然后验收方只要觉得不是太过分就行.")]),a._v(" "),t("p",[a._v("其实这个综合场景, 最后也还是将并发测试中的各个场景去组合起来, 然后大致设置一个比例就行, 因为已经针对各个场景去做过并发测试了. 并且性能消耗最大的那个场景也测试过了, 单个场景的并发性能都能满足了, 那么合并起来肯定也是没有问题的.")]),a._v(" "),t("p",[a._v("所以, 这个综合场景, 其实关注的是多个业务一起请求的时候, 系统的调度和编排能力了, 即某个场景的业务引入的软件的变化会不会对其他业务造成影响和约束和瓶颈. 不过的话, 幸运的是, 在现在的架构下, 不太会出现这种问题, 即不会出现资源互锁或者相互依赖的情况, 这种情况还是比较少的. 因为通常的分布式系统是依赖于各类组件去实现的, 而各类组件想缓存, 文件系统又都是厉害的开源软件, 又通常是无状态的比如kafka和redis这种. 如果出问题的话, 更多的是软件逻辑之间的互锁和约束.")]),a._v(" "),t("h2",{attrs:{id:"交付过程中的性能优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#交付过程中的性能优化"}},[a._v("#")]),a._v(" 交付过程中的性能优化")]),a._v(" "),t("p",[a._v("这个交付过程中, 也是又做了少量的优化, 因为这种验收测试, 通常不会持续很长的时间, 所以, 优化的手段大多是, SQL优化, 而不太可能涉及业务的重构. 另外JVM的优化似乎也就是 挠挠痒, 只能又2-3%的优化表现 (毕竟这么大个系统综合业务这么多, 很难又一种JVM参数去针对多种场景都能适用).")]),a._v(" "),t("p",[a._v("所以, 我记得的就是, 我用火焰图工具, 抓出性能消耗大的场景, 并找出对应模块, 找出对应的sql语句, 然后开发区做了一点简单的优化, 一次来满足性能诉求, 就通常是一点应急的措施, 说起来也是有点无奈的, 在这个过程中, 测试不太能够去做出很多的改进.")]),a._v(" "),t("p",[a._v("其实, 那个时候, 性能验收人员, 也有建议过我换一个GC, 也就是最近比较流程的GC, 实际上, 我后来去测试了之后, 也没有发现有很大的变化. 反而是, 性能的呈现周期性的波峰, 就让我很头疼, 根据我的分析, 这大概就是, 业务架构直接使用开源组件, 并没有做出充分的编排和调度, 和容量设计, 并不能充分调度CPU的性能, 所以, 业务的处理能力会随着组件中的缓存而变化, 请求的响应时间也呈现对应的变化. 这看起来是通用软件架构的通病(这个架构就是Linux +k8s+ redis+kafka+微服务)")]),a._v(" "),t("p",[a._v("所以, 原以为这个最能让我兴奋的阶段, 反而是变成了一个难啃的骨头")]),a._v(" "),t("h2",{attrs:{id:"报告编写"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#报告编写"}},[a._v("#")]),a._v(" 报告编写")]),a._v(" "),t("p",[a._v("毕竟是给甲方做性能交付, 在我们公司性能测试能够力不是很好的情况下, 至少说是, 没有好过客户公司的验收能力的情况下, 这个时候会直接采用客户公司的模板, 因为这样子, 能够比较清晰的去展现甲方所要关注的事情.")]),a._v(" "),t("p",[a._v("印象中, 报告的编写, 就是将各类数据填充上去, 附上测试数据和用例, 并且对负载测试和并发测试场景, 做相关的解释说明. 做解释的过程也是比较难的, 既然说明性能能力满足, 又要避免过度暴露自己的问题")]),a._v(" "),t("h2",{attrs:{id:"和甲方验收同事的相处"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#和甲方验收同事的相处"}},[a._v("#")]),a._v(" 和甲方验收同事的相处")]),a._v(" "),t("p",[a._v("对于验收同事而言, 验收只是他的工作内容, 他其实也是按照公司的期望或者领导的期望去验收软件, 通常不会为难供应商, 但是也不会让一些低级的问题给漏掉.")]),a._v(" "),t("p",[a._v("其实在这个过程中, 我还是和验收同事学习到了很多东西, 那段时间算是我学到了很多知识, 我和他也一起吃过很多次饭, 大家相处的也都比较开心.")])])}),[],!1,null,null,null);t.default=s.exports}}]);