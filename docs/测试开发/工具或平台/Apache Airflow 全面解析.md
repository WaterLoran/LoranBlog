## Apache Airflow å…¨é¢è§£æ  
â€”â€” æ•°æ®å·¥ä½œæµçš„è°ƒåº¦ä¸ç¼–æ’å¼•æ“  

---

### ä¸€ã€Airflow æ ¸å¿ƒå®šä½  
**è§£å†³ç—›ç‚¹**ï¼š  
å¤æ‚æ•°æ®ç®¡é“çš„å®šæ—¶è°ƒåº¦ã€ä»»åŠ¡ä¾èµ–ç®¡ç†ã€é”™è¯¯é‡è¯•ä¸ç›‘æ§  
**æ ¸å¿ƒèƒ½åŠ›**ï¼š  
```mermaid
graph LR
A[ä»»åŠ¡ç¼–æ’] --> B[å®šæ—¶è°ƒåº¦]
A --> C[ä¾èµ–ç®¡ç†]
A --> D[é”™è¯¯å¤„ç†]
A --> E[å¯è§†åŒ–ç›‘æ§]
```

---

### äºŒã€æ ¸å¿ƒæ¶æ„ç»„ä»¶  
| **ç»„ä»¶**        | **ä½œç”¨**                                   | å…³é”®æŠ€æœ¯æ ˆ               |
| --------------- | ------------------------------------------ | ------------------------ |
| **Scheduler**   | å¤§è„‘ï¼šè§£æDAGã€è§¦å‘ä»»åŠ¡ã€ç›‘æ§çŠ¶æ€          | å¤šè¿›ç¨‹/åˆ†å¸ƒå¼é”          |
| **Executor**    | æ‰§è¡Œå™¨ï¼šæ§åˆ¶ä»»åŠ¡è¿è¡Œæ–¹å¼ï¼ˆæœ¬åœ°/å®¹å™¨/é›†ç¾¤ï¼‰ | Local/Celery/K8sExecutor |
| **Web Server**  | å¯è§†åŒ–ï¼šä»»åŠ¡ç›‘æ§/æ—¥å¿—æŸ¥çœ‹/æ‰‹åŠ¨æ“ä½œ         | Flask + React            |
| **Metadata DB** | å­˜å‚¨ä¸­å¿ƒï¼šä¿å­˜DAGå®šä¹‰/ä»»åŠ¡çŠ¶æ€/å†å²è®°å½•    | PostgreSQL/MySQL         |
| **Worker**      | æ‰§è¡Œå•å…ƒï¼šå®é™…è¿è¡Œä»»åŠ¡ä»£ç çš„èŠ‚ç‚¹           | è¿›ç¨‹/Dockerå®¹å™¨          |

---

### ä¸‰ã€æ ¸å¿ƒæ¦‚å¿µè¯¦è§£  

#### 1. **DAG (æœ‰å‘æ— ç¯å›¾)**  
- **æœ¬è´¨**ï¼šç”¨Pythonä»£ç å®šä¹‰çš„ä»»åŠ¡æµç¨‹å›¾  
- **ç‰¹æ€§**ï¼š  
  - èŠ‚ç‚¹ = ä»»åŠ¡ï¼ˆOperatorï¼‰  
  - è¾¹ = æ‰§è¡Œé¡ºåºä¾èµ–  
  - ç¦æ­¢å¾ªç¯ä¾èµ–  

**ç¤ºä¾‹ä»£ç **ï¼š  
```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def extract(): print("æ•°æ®æŠ½å–")
def load(): print("æ•°æ®åŠ è½½")

with DAG(
    dag_id="etl_pipeline",
    schedule_interval="0 3 * * *",  # æ¯å¤©3ç‚¹æ‰§è¡Œ
    start_date=datetime(2023, 1, 1)
) as dag:
    t1 = PythonOperator(task_id="extract", python_callable=extract)
    t2 = PythonOperator(task_id="load", python_callable=load)
    t1 >> t2  # ä¾èµ–å…³ç³»
```

#### 2. **Operator (ä»»åŠ¡ç®—å­)**  
| **ç±»å‹** | ä½œç”¨               | å¸¸ç”¨å®ç°                        |
| -------- | ------------------ | ------------------------------- |
| æ‰§è¡Œç®—å­ | è¿è¡Œå…·ä½“æ“ä½œ       | `PythonOperator` `BashOperator` |
| ä¼ è¾“ç®—å­ | æ•°æ®è½¬ç§»           | `MySqlToGcsOperator`            |
| ä¼ æ„Ÿå™¨   | ç­‰å¾…å¤–éƒ¨æ¡ä»¶       | `S3KeySensor`                   |
| å®¹å™¨ç®—å­ | åœ¨Dockerä¸­è¿è¡Œä»»åŠ¡ | `DockerOperator`                |

#### 3. **ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸ**  
```mermaid
stateDiagram-v2
    [*] --> scheduled
    scheduled --> queued
    queued --> running
    running --> success
    running --> failed
    failed --> retrying
    retrying --> running
```

---

### å››ã€æ ¸å¿ƒå·¥ä½œåŸç†è§£æ  

#### 1. **è°ƒåº¦æœºåˆ¶**  
```mermaid
sequenceDiagram
    Scheduler->>MetadataDBï¼š æ‰«æå¾…æ‰§è¡ŒDAG
    Scheduler->>Executorï¼š åˆ†å‘ä»»åŠ¡å®ä¾‹
    Executor->>Workerï¼š æ‰§è¡Œå…·ä½“ä»»åŠ¡
    Worker-->>MetadataDBï¼š æ›´æ–°ä»»åŠ¡çŠ¶æ€
    MetadataDB-->>WebServerï¼š åˆ·æ–°UIå±•ç¤º
```

#### 2. **æ—¶é—´çª—å£æ§åˆ¶**  
| **å‚æ•°**            | ä½œç”¨                         | ç¤ºä¾‹å€¼               |
| ------------------- | ---------------------------- | -------------------- |
| `start_date`        | DAGé¦–æ¬¡å¯è°ƒåº¦æ—¥æœŸ            | `datetime(2023,1,1)` |
| `schedule_interval` | æ‰§è¡Œå‘¨æœŸï¼ˆcronè¡¨è¾¾å¼ï¼‰       | `"30 2 * * *"`       |
| `end_date`          | DAGåœæ­¢è°ƒåº¦æ—¥æœŸï¼ˆå¯é€‰ï¼‰      | `datetime(2024,1,1)` |
| `catchup`           | æ˜¯å¦è¡¥è·‘å†å²ä»»åŠ¡ï¼ˆé»˜è®¤Trueï¼‰ | `False`              |

---

### äº”ã€é«˜çº§ç‰¹æ€§  

#### 1. **åŠ¨æ€DAGç”Ÿæˆ**  
```python
for table in ['users', 'orders']:
    with DAG(f"load_{table}", ...) as dag:
        load_task = SqlOperator(sql=f"LOAD TABLE {table}...")
```

#### 2. **è·¨DAGä¾èµ–**  
```python
wait_main = ExternalTaskSensor(
    task_id="wait_main_etl",
    external_dag_id="main_etl",
    external_task_id="transform_complete"
)
```

#### 3. **é”™è¯¯è‡ªåŠ¨æ¢å¤**  
```python
task = PythonOperator(
    task_id="retry_task",
    retries=3,                    # é‡è¯•æ¬¡æ•°
    retry_delay=timedelta(minutes=5),  # é‡è¯•é—´éš”
    on_failure_callback=alert_slack  # å¤±è´¥å›è°ƒ
)
```

---

### å…­ã€ç”Ÿäº§çº§éƒ¨ç½²æ–¹æ¡ˆ  

#### 1. **æ‰§è¡Œå™¨é€‰å‹å¯¹æ¯”**  
| **Executor**       | é€‚ç”¨åœºæ™¯     | ä¼˜åŠ¿              | ç¼ºç‚¹             |
| ------------------ | ------------ | ----------------- | ---------------- |
| LocalExecutor      | å•æœºæµ‹è¯•     | ç®€å•æ˜“ç”¨          | æ— å¹¶è¡Œ/æ— å®¹é”™    |
| CeleryExecutor     | ç”Ÿäº§çº§åˆ†å¸ƒå¼ | æ°´å¹³æ‰©å±•/ä»»åŠ¡é˜Ÿåˆ— | éœ€Redis/RabbitMQ |
| KubernetesExecutor | å®¹å™¨åŒ–ç¯å¢ƒ   | å¼¹æ€§ä¼¸ç¼©/èµ„æºéš”ç¦» | è¿ç»´å¤æ‚åº¦é«˜     |

#### 2. **é«˜å¯ç”¨æ¶æ„**  
```mermaid
graph TB
    LB[è´Ÿè½½å‡è¡¡] --> Web1[Web Server]
    LB --> Web2[Web Server]
    
    Scheduler1 -->|çƒ­å¤‡| Scheduler2
    Scheduler1 --> MetaDB[(å…ƒæ•°æ®åº“)]
    
    Celery[Redis] --> Worker1[Worker]
    Celery --> Worker2[Worker]
    Celery --> Worker3[Worker]
```

---

### ä¸ƒã€å…¸å‹åº”ç”¨åœºæ™¯  

#### 1. **æ•°æ®ç®¡é“**  
```mermaid
graph LR
    A[æ•°æ®æŠ½å–] --> B[æ•°æ®æ¸…æ´—]
    B --> C[æ¨¡å‹è®­ç»ƒ]
    C --> D[ç»“æœæ¨é€]
```

#### 2. **ç³»ç»Ÿè¿ç»´**  
- æ¯æ—¥æ•°æ®åº“å¤‡ä»½  
- æ—¥å¿—è½®è½¬æ¸…ç†  
- æœåŠ¡å¥åº·æ£€æŸ¥  

#### 3. **ä¸šåŠ¡ç›‘æ§**  
- æ•°æ®è´¨é‡æ ¡éªŒ  
- æŠ¥è¡¨è‡ªåŠ¨ç”Ÿæˆ  
- å¼‚å¸¸å‘Šè­¦è§¦å‘  

---

### å…«ã€æœ€ä½³å®è·µæŒ‡å—  

1. **DAGè®¾è®¡åŸåˆ™**  
   - åŸå­æ€§ï¼šæ¯ä¸ªä»»åŠ¡åªåšä¸€ä»¶äº‹  
   - å¹‚ç­‰æ€§ï¼šé‡å¤æ‰§è¡Œç»“æœä¸€è‡´  
   - æ¨¡å—åŒ–ï¼šå¤ç”¨å…¬å…±ç»„ä»¶  

2. **æ€§èƒ½ä¼˜åŒ–æŠ€å·§**  
   ```ini
   # airflow.cfg
   [core]
   parallelism = 32  # å…¨å±€å¹¶å‘ä»»åŠ¡æ•°
   dag_concurrency = 16  # å•ä¸ªDAGå¹¶å‘æ•°
   [scheduler]
   min_file_process_interval = 30  # DAGæ–‡ä»¶æ‰«æé—´éš”
   ```

3. **å®‰å…¨åŠ å›º**  
   - RBACï¼ˆåŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ï¼‰  
   - æ•æ„Ÿä¿¡æ¯å­˜å…¥`Connections`åŠ å¯†ç®¡ç†  
   - ç½‘ç»œéš”ç¦»ï¼ˆWorkerè¿è¡Œåœ¨å†…ç½‘ï¼‰  

---

### ä¹ã€ç”Ÿæ€å·¥å…·é›†æˆ  
| **å·¥å…·**               | é›†æˆæ–¹å¼              | ç”¨é€”               |
| ---------------------- | --------------------- | ------------------ |
| **Great Expectations** | PythonOperatorè°ƒç”¨    | æ•°æ®è´¨é‡æ ¡éªŒ       |
| **Docker**             | DockerOperator        | ç¯å¢ƒéš”ç¦»çš„ä»»åŠ¡æ‰§è¡Œ |
| **Kubernetes**         | KubernetesPodOperator | åŠ¨æ€å®¹å™¨åŒ–ä»»åŠ¡     |
| **Prometheus**         | æš´éœ²`/metrics`ç«¯ç‚¹    | ç³»ç»Ÿç›‘æ§æŒ‡æ ‡é‡‡é›†   |

---

### åã€é€‚ç”¨åœºæ™¯ vs æ›¿ä»£æ–¹æ¡ˆ  
| **åœºæ™¯**       | æ¨èå·¥å…·    | åŸå›                   |
| -------------- | ----------- | --------------------- |
| åˆ†é’Ÿçº§å®šæ—¶ä»»åŠ¡ | Airflow     | å¤æ‚ä¾èµ–ç®¡ç†/é‡è¯•æœºåˆ¶ |
| å®æ—¶æµå¤„ç†     | Flink/Spark | ä½å»¶è¿Ÿå¤„ç†èƒ½åŠ›        |
| ç®€å•cronä»»åŠ¡   | crontab     | é›¶è¿ç»´å¼€é”€            |
| æ— æœåŠ¡å™¨ä»»åŠ¡   | AWS Lambda  | æŒ‰éœ€ä»˜è´¹/è‡ªåŠ¨æ‰©ç¼©å®¹   |

> ğŸ”¥ **æ ¸å¿ƒä»·å€¼**ï¼š  
> 1. **ä»£ç å³é…ç½®**ï¼šPythonå®šä¹‰å·¥ä½œæµï¼Œç‰ˆæœ¬å¯æ§  
> 2. **å¯è§†åŒ–è¿ç»´**ï¼šWeb UIå®æ—¶ç›‘æ§ä»»åŠ¡çŠ¶æ€  
> 3. **æ‰©å±•æ€§å¼º**ï¼šæ”¯æŒè‡ªå®šä¹‰Operator/Hook  
> 4. **ç¤¾åŒºç”Ÿæ€**ï¼š300+å®˜æ–¹é›†æˆç»„ä»¶  

[å®˜æ–¹æ–‡æ¡£](https://airflow.apache.org/)ï½œ[GitHub](https://github.com/apache/airflow)ï½œ[å¿«é€Ÿå…¥é—¨](https://airflow.apache.org/docs/apache-airflow/stable/start.html)