#  devops过程中如何尽做全面的回归测试 

## 问题背景

公司某个项目搞大客户定制化开发, 客户那边是大公司, 目的是要建设公司的IT体系, (客户公司是制造业非IT企业), 建设IT体系是为了助力生产和管理, 以及客户方主要做的是集成, 即将多个供应商系统集成起来. 目前客户方采用的是devops研发模式. 

在多期开发中的某一期, 给我放提出了, 几个小的需求, 我们提测到客户公司的测试环境之后, 对方期望我们做回归测试. 问题的难点在于, 公司给他们做定制化的时候, 都没有规范的测试用例, 之前也没有做严谨的全面的全面回归测试, 通常是会发现简单回归测试之后(大概率就是凭感觉去查看哪里有问题就去检查哪里, 检查到一定时间之后, 就算结束了)

所以, 这次轮到我来做之后, 我就感受到了小小的茫然, 我甚至不知道回归标准具体要到什么程度, 也没有一个可以参考的标准, 也没有什么方法和经验. 但是我又不想随意测试, 然后混过去, 所以, 我思考调研起来有什么方案和方法是可以采取的, 并且期望是可以固化下来的. 这样子可以避免重复的劳动, 以及降低该项工作的难度和风险和人力消耗.

## 找GPT询问了一下意见

```markdown
在DevOps过程中，全面的回归测试是确保代码更改不会引入新的错误并破坏现有功能的关键步骤。以下是一些策略和实践，可以帮助你尽可能地进行全面的回归测试：

1. 自动化测试
自动化测试是回归测试的基础。通过自动化脚本，可以快速、反复地运行大量测试用例。

单元测试：确保每个单独的模块或函数按照预期工作。
集成测试：验证不同模块之间的交互是否正常。
端到端测试：模拟用户行为，确保整个系统从前端到后端都能正常运行。

2. 持续集成/持续部署（CI/CD）
CI/CD管道可以自动化构建、测试和部署过程，每次代码更改时都触发回归测试。

持续集成：每次代码提交后自动触发构建和测试，及时发现问题。
持续部署：在测试通过后自动部署到生产环境。
3. 测试覆盖率
确保测试覆盖了代码的各个部分，包括边界情况和异常处理。

代码覆盖率工具：使用工具（如JaCoCo、Coveralls）来测量测试覆盖率，并找出未被测试的代码区域。
功能覆盖率：确保所有功能路径和用户场景都被测试到。
4. 回归测试套件
创建一个专门的回归测试套件，包含所有关键功能和核心业务逻辑的测试用例。

关键路径测试：识别并测试最重要和最常用的功能路径。
历史缺陷测试：包括过去曾经发现和修复的缺陷，以防止它们再次出现。
5. 基于风险的测试
根据功能的重要性和更改的影响范围，优先测试可能受影响的高风险区域。

风险评估：评估哪些部分的更改可能对系统造成重大影响，并优先对这些部分进行测试。
影响分析：分析代码更改的影响范围，以决定需要测试的范围。
6. 并行测试
利用现代CI/CD工具的并行测试功能，缩短测试时间。

并行化：将测试用例分布在多个测试环境或机器上同时运行。
分布式测试：使用云服务或集群进行大规模并行测试。
7. 测试环境一致性
确保测试环境与生产环境尽可能一致，以提高测试结果的可靠性。

环境配置管理：使用配置管理工具（如Ansible、Chef、Puppet）保持环境一致性。
容器化：使用容器技术（如Docker）创建一致的测试环境。
8. 持续监控和反馈
在生产环境中持续监控系统的表现，并将反馈循环回开发和测试过程中。

监控工具：使用监控工具（如Prometheus、Grafana）实时监控系统性能和错误。
反馈机制：建立反馈机制，将生产环境中的问题反馈给开发和测试团队。
总结
全面的回归测试需要结合自动化、CI/CD、测试覆盖率、风险评估、并行测试、环境一致性和持续监控等多种策略。这些策略的综合应用可以确保在DevOps过程中高效且全面地进行回归测试，从而保证系统的稳定性和可靠性。
```

于是挨个分析

1. 自动化测试
   目前因为是大客户定制化开发, 所以不编写自动化脚本来回归. 以及在之前的时候, 因为功能测试不完善, 导致漏测出去的问题实在是多, 可能有30-40%会是改动引发的问题, 所以,反馈到售后的BUG每天大概有5个(多个大客户的反馈BUG总数), 然而自动化所发现的通用版本的改动引发BUG每周2个, 效率上实在是不划算, 所以最终自动化测试因为功能测试的原因, 而被迫暂停了. 就目前而言, 自动化脚本的积累不足, 数量不够, 覆盖不够全面, 更加谈不上精准.
   所以, 这块的话, 只能是尽可能利用上已有的脚本了, 并不能做过多的期望.
2. 持续集成/持续部署(CI/CD)
   其实这部分在我们公司那边, 主要是体现在两方面, 一个是提交代码之后出发的自动化测试, 另外一个是提交代码到公用环境, 所有人员直接众测. 以下是分析, 触发自动化测试强依赖于自动化脚本数量, 不然效果不明显. 另外一个出发所有人员直接内部众测, 也存在一定的不足, 因为每个人有他自己的工作和目的, 所以必然不会做充分的思考分析和探索式测试和全面的对比分析. 所以, 这种方式只能发现一些明显的BUG. 一些易用性的BUG, 数据准确性的BUG, 还是比较难发现的.
3. 测试覆盖率
   这个的基础工具的难度还是比较大的, 理论上是可行的, 但是还需要依赖于测试人员能够直接读懂未覆盖的代码并且新增加强测试用来来覆盖, (或者是开发来协助说明那些功能点要测试), 比如在我们内部会将镜像推送到公共环境, 所有测试都会在一起测试, 然后覆盖率就基于这个环境去统计. 或许可以发现, 哪些代码新增之后, 却永远不会被覆盖到. (但是在K8s场景可能会稍微麻烦). 但是我们这边还没有开发出对应的配套工具, 该项操作的可实施性的不太可行
4. 回归测试套件
   这个偏向于功能测试, 或者手工测试. GPT所提到的有设计到关键路径测试, 历史缺陷测试. 个人认为是个不错的选择. 关键路径测试可以测试常用功能路径, 避免出现重大影响问题, 保障核心价值. 历史缺陷测试能够尽可能的发现开发经常改动引发的模块代码. 也是较为有效的方式, 特别是在短期迭代过程中, 出现的一些问题.
   除了这些点, 我觉得还可以补充一点, 就是checkList检查项, 相对于,关键路径测试, 这个checkList会更加零散, 但覆盖的更多更全, (但是需要有文件积累和沉淀), 以及对于某些个模块的覆盖面会更加全.
5. 基于风险的测试
   对于这个, GPT的意见是, 做评估和影响分析, 类似于单个BUG的回归过程. 偏向于功能测试, 需要业务经验, 在这里是个不错的选择. 但是风险的评估和分析的话, 需要一些配套的工具来配合, 比如最近了解到的jcci工具, 可以根据变更的代码了解到那些接口被影响了, 也就大概知道哪些功能被影响了.
6. 并行测试
   GPT在这里提到的这个, 目的实质上是为了减少自动化测试的时间, 大概经常用于APP测试, 或者是有大量自动化测试用例的软件项目上.
7. 测试环境一致性
   这是一个很常见并且是不错的建议, 在小公司的迭代过程中, 配置数据的管理常常是不太周全的, 比如配置会分布在软件界面上, 运维软件的配置中, 业绩有些可能直接写死在数据库中, 既然这些信息的编写都不周全了, 那么对应的信息同步肯定也是不周全的. 所以, 尝尝会有一些因为配置不好的原因, 导致BUG一楼到客户场景. 而这些devops迭代场景的问题, 瀑布迭代的软件通常会是将所有的数据配置等打包到一起, 在后再去安装, 可靠性就会好很多.
8. 持续监控和反馈
   这个相当于是持续测试, 并期望能够在客户实际使用之前拦截更多的BUG. 但是功能测试的持续测试似乎是不太可行的, 毕竟不可能一直消耗一个人力在某个项目上, 需要是有规划有目的有范围的去做事情. 但是如GPT所说, 持续监控性能确实是一个不错的选择. 反馈机制也是个不错的选择, 目前反应到团队协作中, 就是客户会将问题反馈到售后那边, 然后在反馈回来是个, 不错的做法.

## 最终的结论

在已有的条件基础上, 尽可能的去做充分的回归测试的话, 有下面这些事情可以做.

1. 已有的自动化脚本连跑: 连跑完已有的通用版本的自动化脚本并排查定位, 即做最基本的功能的回归测试
2. 回归套件-关键路径测试: 做一些关键路径的功能测试
3. 回归套件-历史缺陷测试: 挑选最近在其他客户经常出现问题的模块来进行测试
4. 回归套件-checkList测试: 梳理并列举一些常用的测试点, 然后根据用例进行测试
5. 使用jcci分析被影响接口并做测试: 确认这次和上次版本之间的提交差异, 得出影响接口并做测试
6. 确认环境配置一致: 和运维沟通确认, 确保无新增配置, 如有需要做对应测试.







